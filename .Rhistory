df <-
read.csv2(
"across_specialist.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
write.table(
df,
"across_specialist.txt",
append = F,
dec = ".",
col.names = F,
row.names = F,
#sep = \n",
eol = "\n\n"
)
df <-
read.csv2(
"across_specialist.csv",
stringsAsFactors = F,
header = T
)
df <-
read.csv2(
"across_specialist.csv",
stringsAsFactors = F,
header = T
)
df <-
read.csv2(
"across_specialist.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
df <-
read.csv2(
"Across_Specialties.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
write.table(
df,
"across_specialist.txt",
append = F,
dec = ".",
col.names = F,
row.names = F,
#sep = \n",
eol = "\n\n"
)
df <-
read.csv2(
"Across_Specialties.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
write.table(
df,
"Across_Specialties.txt",
append = F,
dec = ".",
col.names = F,
row.names = F,
#sep = \n",
eol = "\n\n"
)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
install.packages("reshape2")
library(reshape2)
install.packages("reshape2")
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
install.packages("data.table")
library(data.table)
data.table
library(data.table)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
metaout <- read_html("25_FRA_out.xml")
df <-
read.csv2(
"Across_Specialties3.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
write.table(
df,
"Across_Specialties3.txt",
append = F,
dec = ".",
col.names = F,
row.names = F,
#sep = \n",
eol = "\n\n"
)
rm(list = ls())
library(rvest)
descr_train<- read_html ("Across_Specialties3.txt")
descr_freq_words<-findFreqTerms(descr_train, 5)
descr_freq_words<-findFreqTerms(descr_train)
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
install.packages("tm")
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
descr_train<- read_html ("Across_Specialties3.txt")
descr_freq_words<-findFreqTerms(descr_train)
source('~/GitHub/E-HEALTH/prova_freq.R')
descr_freq_words<-findFreqTerms(descr_train, 5)
source('~/GitHub/E-HEALTH/prova_freq.R')
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(1,4,5)]
source('~/GitHub/E-HEALTH/prova_freq.R')
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
t4_train$NC.1.0<-factor(t4_train$NC.1.0)
t4_train
descr_freq_words<-findFreqTerms(t4_train, 5)
source('~/GitHub/E-HEALTH/prova_freq.R')
descr_freq_words<-findFreqTerms(t4_train)
descr_corpus <- VCorpus(VectorSource(t4_train$Description))
descr_corpus <- VCorpus(VectorSource(t4_train$description))
t4_train
descr_corpus <- VCorpus(VectorSource(t4_train)
source('~/GitHub/E-HEALTH/prova_freq.R')
descr_corpus <- VCorpus(VectorSource(t4_train)
s
t4_train[0]
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
descr_freq_words<-findFreqTerms(t4_train)
help("findFreqTerms")
descr_freq_words<-findFreqTerms(t4_train,lowfreq = 0, highfreq = Inf)
N<-matrix(t4_train,1);
View(N)
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
N<-matrix(t4_train,inf);
N<-matrix(t4_train, Inf);
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
source('~/GitHub/E-HEALTH/prova_freq.R')
N<-matrix(t4_train);
descr_freq_words<-findFreqTerms(t4_train,lowfreq = 0, highfreq = Inf)
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
source('~/GitHub/E-HEALTH/prova_freq.R')
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
N<-matrix(t4_train);
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
View(N)
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
# make corpus for text mining (data comes from package, for reproducibility)
corpus <- Corpus(VectorSource(training_test_4))
View(corpus)
source('~/GitHub/E-HEALTH/prova_freq.R')
skipWords <- function(x) removeWords(x, stopwords("english"))
funcs <- list(tolower, removePunctuation, removeNumbers, stripWhitespace, skipWords)
a <- tm_map(corpus, FUN = tm_reduce, tmFuns = funcs)
a.dtm1 <- TermDocumentMatrix(a, control = list(wordLengths = c(3,10)))
findFreqTerms(a.dtm1)
findFreqTerms(a.dtm1,2)
m <- as.matrix(a.dtm1)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, N)
m <- as.matrix(training_test_4)
v <- sort(rowSums(m), decreasing=TRUE)
source('~/GitHub/E-HEALTH/prova_freq.R')
df <-
read.csv2(
"Across_Specialties_nostro.csv",
stringsAsFactors = F,
header = T
)
df <- df[,4]
write.table(
df,
"Across_Specialties_nostro.txt",
append = F,
dec = ".",
col.names = F,
row.names = F,
#sep = \n",
eol = "\n\n"
)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
install.packages("reshape2")
reshape2)
library(reshape2)
install.packages("reshape2")
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
metaout <- read_html("Across_nostro_out.xml")
candidate_preferred <- metaout %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
frequenza <- read_html("Across_Specialties3.txt")
df1 <- count(df, frequenza)
View(frequenza)
View(frequenza)
#leggo l'output di metamap
frequenza <- read_html("Across_Specialties3.cvs")
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
frequenza <- read_html("Across_Specialties3.cvs")
#leggo l'output di metamap
frequenza <- read_cvs("Across_Specialties3.cvs")
#leggo l'output di metamap
frequenza <- read.csv2("Across_Specialties3.cvs")
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
frequenza <- read.csv2("Across_Specialties3.cvs")
#leggo l'output di metamap
frequenza <- read.csv2("Across_Specialties3.cvs")
#leggo l'output di metamap
frequenza <- read_html("Across_Specialties3.txt")
candidate_preferred <- metaout %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
candidate_preferred <- frequenza %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
df <- tibble(
"Candidate_Preferred" = candidate_preferred
)
df1 <- count(df, df)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
metaout <- read_html("Across_Specialties3.txt")
candidate_preferred <- metaout %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
df <- tibble(
"Candidate_Preferred" = candidate_preferred
)
df1 <- count(df, "Candidate_Preferred")
df1_sub<-df1 %>% filter(freq >= 10)
View(df1)
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
# make corpus for text mining (data comes from package, for reproducibility)
corpus <- Corpus(VectorSource(training_test_4))
skipWords <- function(x) removeWords(x, stopwords("english"))
funcs <- list(tolower, removePunctuation, removeNumbers, stripWhitespace, skipWords)
a <- tm_map(corpus, FUN = tm_reduce, tmFuns = funcs)
a.dtm1 <- TermDocumentMatrix(a, control = list(wordLengths = c(3,10)))
findFreqTerms(a.dtm1,2)
m <- as.matrix(a.dtm1)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, N)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
N<-matrix(t4_train);
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
metaout <- read_html("Across_Specialties3.txt")
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
invalue <- read_html("Across_Specialties3.txt")
prova <- invalue %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
df <- tibble(
"cate" = prova
)
df1 <- count(df, "cate")
df1_sub<-df1 %>% filter(freq >= 10)
View(df1_sub)
#SECONDO METODO
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
corpus <- Corpus(VectorSource(training_test_4))
skipWords <- function(x) removeWords(x, stopwords("english"))
funcs <- list(tolower, removePunctuation, removeNumbers, stripWhitespace, skipWords)
a <- tm_map(corpus, FUN = tm_reduce, tmFuns = funcs)
a.dtm1 <- TermDocumentMatrix(a, control = list(wordLengths = c(3,10)))
findFreqTerms(a.dtm1,2)
m <- as.matrix(a.dtm1)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, N)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
N<-matrix(t4_train);
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
rm(list = ls())
library(rvest)
library(tidyverse)
library(tm)
training_test_4<-read.csv2("Across_Specialties3.csv",header = T)
# make corpus for text mining (data comes from package, for reproducibility)
corpus <- Corpus(VectorSource(training_test_4))
skipWords <- function(x) removeWords(x, stopwords("english"))
funcs <- list(tolower, removePunctuation, removeNumbers, stripWhitespace, skipWords)
a <- tm_map(corpus, FUN = tm_reduce, tmFuns = funcs)
a.dtm1 <- TermDocumentMatrix(a, control = list(wordLengths = c(3,10)))
findFreqTerms(a.dtm1,2)
m <- as.matrix(a.dtm1)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, N)
t4_train<-training_test_4[which(training_test_4$X=="Test"),c(4)]
N<-matrix(t4_train);
descr_freq_words<-findFreqTerms(N,lowfreq = 0, highfreq = Inf)
#PRIMO METODO
rm(list = ls())
library(rvest)
library(tidyverse)
library(pbapply)
library(reshape2)
library(ggplot2)
library(data.table)
#leggo l'output di metamap
invalue <- read_html("Across_Specialties3.txt")
prova <- invalue %>%
html_nodes("candidatepreferred") %>%
html_text(trim = F)
df <- tibble(
"cate" = prova
)
df1 <- count(df, "cate")
df1_sub<-df1 %>% filter(freq >= 10)
View(df1_sub)
