urlvector<-urlvector[-death_vector[j]]
}
urlvector
for(j in 1:length(death_vector)){
urlvector<-urlvector[-death_vector[j]]
}
urlvector
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
death_vector[2]
death_vector[1]
urlvector[-2]
library(rvest)
library(textcat)
death_vector<-NULL
urlgiappo<-"https://itunes.apple.com/us/app/%D1%8F%D1%81%D0%BC%D0%BE%D0%B3%D1%83/id1435606589?mt=8"
urlrussian<- "https://itunes.apple.com/us/app/cosme-%E5%8C%96%E7%B2%A7%E5%93%81-%E3%82%B3%E3%82%B9%E3%83%A1%E3%81%AE%E3%83%A9%E3%83%B3%E3%82%AD%E3%83%B3%E3%82%B0-%E3%82%AF%E3%83%81%E3%82%B3%E3%83%9F/id793054713?mt=8"
urlenglish<- "https://itunes.apple.com/us/app/human-anatomy-atlas-2019/id1117998129?mt=8"
urlvector<-c(urlenglish,urlrussian,urlgiappo)
len<-length(urlvector)
len
for(i in 1:len) {
page<- read_html(urlvector[i])
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
if(appinfo!="english") {
death_vector<-c(death_vector,i)
}
}
death_vector[1]
urlvector[-2]
tibble(url=urlvector)
tibble(url=urlvector)
language<-NULL
urlgiappo<-"https://itunes.apple.com/us/app/%D1%8F%D1%81%D0%BC%D0%BE%D0%B3%D1%83/id1435606589?mt=8"
urlenglish<- "https://itunes.apple.com/us/app/human-anatomy-atlas-2019/id1117998129?mt=8"
urlrussian<- "https://itunes.apple.com/us/app/cosme-%E5%8C%96%E7%B2%A7%E5%93%81-%E3%82%B3%E3%82%B9%E3%83%A1%E3%81%AE%E3%83%A9%E3%83%B3%E3%82%AD%E3%83%B3%E3%82%B0-%E3%82%AF%E3%83%81%E3%82%B3%E3%83%9F/id793054713?mt=8"
urlvector<-c(urlenglish,urlrussian,urlgiappo)
tibble(url=urlvector)
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
df<-tibble(url=urlvector)
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
df
df<-tibble(url=urlvector, language=language)
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
for(i in 1:len) {
page<- read_html(urlvector[i])
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language<-c(language,appinfo)
}
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
df
df_english_only<-df[which(language=="english")]
View(df_english_only)
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
View(df_english_only)
read.csv2("app_M_H&F.csv")
df<-read.csv2("app_M_H&F.csv")
View(df)
df_url_subset<-subset(df_all_languages[,2]
df_url_subset<-subset(df_all_languages[,2])
df_url_subset<-df_all_languages[,2]
df_all_languages<-read.csv2("app_M_H&F.csv")
df_url_subset<-df_all_languages[,2]
df_url_subset<-df_all_languages[2,]
View(df_url_subset)
df_url_subset<-df_all_languages[,select(df_all_languages$URL)]
df_url_subset<-df_all_languages[,df_all_languages$URL]
df_url_subset<-df_all_languages$URL
language<-NULL
df_all_languages<-read.csv2("app_M_H&F.csv")
df_url_subset<-df_all_languages$URL
df_url_subset<-select(df_all_languages, df_all_languages$URL)
df_url_subset<-df_url_subset[,df_all_languages$URL]
df_url_subset<-df_url_subset[,"URL"]
library(dplyr)
df_url_subset<-select(df_all_languages, URL)
View(df_url_subset)
len<-length(df_url_subset$URL)
len
page<- read_html(df_url_subset$URL[2])
df_sub<-select(df_all_languages, URL)
library(rvest)
library(dplyr)
library(textcat)
language<-NULL
df_all_languages<-read.csv2("app_M_H&F.csv")
df_sub<-select(df_all_languages, URL)
df_sub[2]
df_sub[[2]]
df_sub[3,1]
View(df_all_languages)
df_all_languages<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
View(df_all_languages)
df_sub<-select(df_all_languages, URL)
df_sub[3,1]
df_sub[3]
df_sub[[3]]
df_subset<-select(df_all_languages, URL)
library(rvest)
library(textcat)
library(dplyr)
language<-NULL
df_subset<-select(df_all_languages, URL)
df_all_languages<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
len<-length(df_url_subset$URL)
library(rvest)
library(textcat)
library(dplyr)
language<-NULL
df_all_languages<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
df_subset<-select(df_all_languages, URL)
len<-length(df_url_subset$URL)
len<-length(df_subset$URL)
len
df_subset$URL[1]
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
df_subset<-select(df_all_languages, URL)
language<-NULL
df_subset<-select(df_all_languages, URL)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
len<-length(df_subset$URL)
df_subset$URL[1]
len
for(i in 1:len) {
page<- read_html(df_subset$URL[i])
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
df_all_languages<-df%>%
mutate(language=language)
install.packages("tictoc")
library(tictoc)
tic()
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
df_subset<-select(df_all_languages, URL)
df_subset$URL[1]
len<-length(df_subset$URL)
len
toc()
tic()
for(i in 1:len) {
print(i)
page<- read_html(df_subset$URL[i])
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
toc()
last(language)
anyDuplicated(df)
source('~/GitHub/E-HEALTH/R script/mergetables.r', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
#Esistono elementi doppi nel dataframe?
anyDuplicated.data.frame(my.df)
#Esistono elementi doppi nel dataframe?
anyDuplicated.data.frame(my.df)
#Sembra di no, per sicurezza si eliminano i duplicati
my.new.df <- my.df[!duplicated(paste(my.df$Name, my.df$URL, my.df$ID, my.df$X)),]
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
View(my.df)
anyDuplicated(my.df)
#Sembra di no, per sicurezza si eliminano i duplicati
my.new.df <- my.df[!duplicated(paste(my.df$Name, my.df$URL, my.df$ID, my.df$X)),]
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE, row.names=FALSE)
page<- read_html(df_subset$URL[106])
page<-read_html(curl(df_subset$URL[106], handle = curl::new_handle("useragent" = "Mozilla/5.0")))
library(curl)
page<-read_html(curl(df_subset$URL[106], handle = curl::new_handle("useragent" = "Mozilla/5.0")))
source('~/GitHub/E-HEALTH/R script/language_detector.r', echo=TRUE)
try(
page<- read_html(df_subset$URL[106])
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
)
try(
page<- read_html(df_subset$URL[106]))
tic()
for(i in 1:len) {
print(i)
try(
page<- read_html(df_subset$URL[i]))
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
toc()
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE, row.names=FALSE)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df_all_languages, URL)
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
df_subset<-select(df, URL)
df_subset$URL[1]
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset$URL[1]
len<-length(df_subset$URL)
len
tic()
for(i in 1:len-123340) {
print(i)
try(
page<- read_html(df_subset$URL[i]))
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
toc()
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset$URL[1]
len<-length(df_subset$URL)
len
tic()
for(i in 1:len-123340) {
print(i)
try(
page<- read_html(df_subset$URL[i]))
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
toc()
try(
page<- read_html(df_subset$URL[i]))
try(
page<- read_html(df_subset$URL[8]))
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
for(i in 1:108) {
print(i)
try(
page<- read_html(df_subset$URL[i]))
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language[i]<-appinfo
}
toc()
df_all_languages<-df%>%
mutate(language=language)
toc()
languages
language
install.packages("gpuR")
library(gpur)
lingua<-NULL
lingua<-c(lingua, 1)
lingua<-c(lingua, 2)
lingua<-c(lingua, 3)
getlanguage<-function(url){
descriptions<-null
page<-read_html(url)
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
language<-c(language,appinfo)
}
lapply(df_subset,1,getlanguage)
lapply(df_subset,2,getlanguage)
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset$URL[1]
len<-length(df_subset$URL)
len
tic()
lapply(df_subset,2,getlanguage)
toc()
View(page)
View(df_subset)
lapply(df_subset,getlanguage)
lapply(df_subset,getlanguage)
language<-null
language<-NULL
lapply(df_subset,getlanguage)
lapply(df_subset,getlanguage)
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset$URL[1]
len<-length(df_subset$URL)
len
tic()
lapply(df_subset,getlanguage)
lapply(df_subset,getlanguage)
df_subset$URL
lapply(df_subset$URL,getlanguage)
lapply(df_subset,is.character)
lapply(df_subset,1,is.character)
apply(df_subset,1,is.character)
apply(df_subset,1,getlanguage)
apply(df_subset,1,getlanguage)
sapply(df_subset,1,getlanguage)
sapply(df_subset,getlanguage)
sapply(df_subset,getlanguage, df_subset$URL)
sapply(df_subset[1:108],getlanguage, df_subset$URL)
sapply(df_subset[1:108,],getlanguage, df_subset$URL)
sapply(df_subset[1:108,],getlanguage)
sapply(df_subset[1:108,],getlanguage(url))
languages<-sapply(df_subset[1:108,],getlanguage(url))
df_subset[1:108,]
languages<-sapply(df_subset[1:108,],function(url) getlanguage(url))
library(tidyverse)
map(getlanguage, df_subset[1:108,])
?map
map
languages<-map(df_subset[1:108,],getlanguage)
getlanguage<-function(url){
page<-read_html(url)
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat()
return(appinfo)
}
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset$URL
languages<-map(df_subset[1:108,],getlanguage)
languages<-map(df_subset[1:10,],getlanguage)
tic()
languages<-map(df_subset[1:10,],getlanguage)
toc()
languages<-map(df_subset[1:100,],getlanguage)
languages
unlist(languages)
languages<-map(df_subset,getlanguage)
languages<-map(df_subset$URL,getlanguage)
tic()
languages<-map(df_subset$URL,getlanguage)
languages<-map(df_subset[106],getlanguage)
languages<-map(df_subset[106,],getlanguage)
url<-df_subset[106,]
getlanguage(url)
getlanguage(url)
getlanguage(url)
getlanguage(url)
tryCatch(
page<-read_html(url)
appinfo<-page%>%
rvest::html_nodes(".section__description .we-clamp__contents")%>%
rvest::html_text(trim=TRUE)%>%
textcat(),
error = function(e){NA})
tic()
languages<-map(df_subset[106,],getlanguage)
languages<-map(df_subset[106,],getlanguage)
languages<-map(df_subset[105,],getlanguage)
languages<-map(df_subset[107,],getlanguage)
languages<-map(df_subset["108",],getlanguage)
df_subset <- Data %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset_lang <- df_subset[90:110,] %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset[90:110,]
df_subset<-select(df[90:110,], URL)
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
View(df_subset_lang)
install.packages("pbapply")
library(pbapply)
pbsapply(df_subset, function(url){
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(pbapply)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(pbapply)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
len<-length(df_subset$URL)
len
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_all_languages<-df%>%
mutate(language=language)
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
2+2
# 1: Caricamento librerie ####
# General-purpose data wrangling
library(tidyverse)
source('~/GitHub/E-HEALTH/R script/getinfo.r', echo=TRUE)
install.packages("stringi")
source('~/GitHub/E-HEALTH/R script/getinfo.r', echo=TRUE)
