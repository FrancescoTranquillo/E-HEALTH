textcat(),
NA)(URL))
df_subset_lang <- df_subset[90:110,] %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset[90:110,]
df_subset<-select(df[90:110,], URL)
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
View(df_subset_lang)
install.packages("pbapply")
library(pbapply)
pbsapply(df_subset, function(url){
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(pbapply)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(pbapply)
language<-NULL
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
len<-length(df_subset$URL)
len
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_all_languages<-df%>%
mutate(language=language)
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
2+2
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(pbapply)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
len<-length(df_subset$URL)
len
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
View(df_subset)
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(df_subset$URL))
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(A))
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(url),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(URL = as.character(URL),    # Convert factors to character for read_html
languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
View(df_subset)
pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_subset_lang <-pbsapply(df_subset, function(url){
df_subset_lang <- df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
df_subset_lang <-pbsapply(df_subset, function(url){
df_subset %>% rowwise() %>%     # Evaluate each row (URL) separately
mutate(languages = possibly(~.x %>% read_html() %>%    # Try to take a URL, read it,
html_nodes(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)%>%
textcat(),
NA)(URL))
})
View(df_subset_lang)
progress_estimated(
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
)
View(df_subset_lang)
require("progress")
install.packages("progress")
library(progress)
language<-NULL
pb <- progress_bar$new(
format = "  downloading [:bar] :percent in :elapsed",
total = 100, clear = FALSE, width= 60)
for (i in 1:100) {
pb$tick()
Sys.sleep(1 / 100)
}
p <- progress_estimated(3)
p$tick()
p$tick()
p$tick()
p$tick()
p<-progress_estimated(123347)
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p$tick()
p<-progress_estimated(123347)
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat()%>%
p$tick,
NA)(URL))
p<-progress_estimated(123347)
function() {
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
p$tick
}
bigdata<-function() {
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
p$tick
}
bigdata()
pb <- progress_bar$new(
format = "(:spin) [:bar] :percent",
total = 30, clear = FALSE, width = 60)
for (i in 1:30) {
pb$tick()
Sys.sleep(3 / 100)
}
pb <- progress_bar$new(
format = "  downloading :what [:bar] :percent eta: :eta",
clear = FALSE, total = 200, width = 60)
f <- function() {
for (i in 1:100) {
pb$tick(tokens = list(what = "foo   "))
Sys.sleep(2 / 100)
}
for (i in 1:100) {
pb$tick(tokens = list(what = "foobar"))
Sys.sleep(2 / 100)
}
}
f()
Sys.sleep(2)
library(tidyverse)
arduously_long_nchar <- function(input_var, .pb=NULL) {
if ((!is.null(.pb)) && inherits(.pb, "Progress") && (.pb$i < .pb$n)) .pb$tick()$print()
Sys.sleep(1)
nchar(input_var)
}
pb <- progress_estimated(length(letters))
map_int(letters, arduously_long_nchar, .pb=pb)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(progress)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
len<-length(df_subset$URL)
len
df_subset<-select(df, URL)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
warnings()
df_subset<-sample(df_subset, 2000)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset<-sample(df_subset, 2000)
df_subset<-sample(df_subset, 2000, replace=TRUE)
df_subset<-sample(df_subset, 2000, replace=TRUE)
df_subset<-sample(df_subset, 20, replace=TRUE)
df_subset_random<-sample(df_subset, 20, replace=TRUE)
df_subset_random<-sample(df_subset, 1500)
df_subset_random<-df_subset[sample(nrow(df_subset), "1500"), ]
View(df_subset_random)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset_random<-df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-select(df, URL)
df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-df_subset[sample(nrow(df_subset), "1500"), ]
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
df_subset<-df_subset[sample(nrow(df_subset), "100"), ]
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "100"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
View(df_subset_lang)
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "3000"), ]
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
####RUN####
df_subset<-select(df, URL)
####RUN####
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "3000"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
####r####
df_english_only<-df_subset_lang[which(language=="english"),]
View(df_subset_lang)
####r####
tic()
toc()
tic()
df_english_only<-df_subset_lang[which(languages=="english"),]
toc()
##
tic()
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
toc()
write.csv2(my.new.df, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
View(df_subset_lang)
View(df)
View(df_english_only)
write.csv2(df_english_only, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
write.csv2(df_subset_lang, "app_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
anyDuplicated(df_english_only)
anyDuplicated(df_subset_lang)
if(anyDuplicated(df_subset_lang)>0){
df_subset_lang <- df_subset_lang[!duplicated(paste(df_subset_lang$URL, df_subset_lang$languages)),]
}
anyDuplicated(df_subset_lang)
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
anyDuplicated(df_english_only)
write.csv2(df_subset_lang, "app_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
write.csv2(df_english_only, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
df_app<-select(df$Name, df$ID, df_english_only)
View(df)
df_app<-inner_join(df, df_english_only, by(URL=URL))
df_app<-inner_join(df, df_english_only, by("URL"="URL"))
df_app<-inner_join(df, df_english_only, by="URL"="URL")
df_app<-inner_join(df, df_english_only, by=c("URL"="URL")
df_app<-inner_join(df, df_english_only, by=c("URL"="URL"))
df_app<-inner_join(df, df_english_only, by="URL")
View(df_app)
anyDuplicated(df_app)
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
anyDuplicated(df_app)
if(anyDuplicated(df_subset_lang)>0){
df_subset_lang <- df_subset_lang[!duplicated(paste(df_subset_lang$URL, df_subset_lang$languages)),]
}
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
tic()
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
toc()
write.csv2(df_subset_lang, "subset_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
write.csv2(df_english_only, "subset_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
write.csv2(df_app, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
