library(rvest)
library(textcat)
library(dplyr)
library(tictoc)
library(curl)
library(tidyverse)
library(progress)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df[90:110,], URL)
df_subset$URL
len<-length(df_subset$URL)
len
df_subset<-select(df, URL)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
<<<<<<< Updated upstream
warnings()
df_subset<-sample(df_subset, 2000)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset<-sample(df_subset, 2000)
df_subset<-sample(df_subset, 2000, replace=TRUE)
df_subset<-sample(df_subset, 2000, replace=TRUE)
df_subset<-sample(df_subset, 20, replace=TRUE)
df_subset_random<-sample(df_subset, 20, replace=TRUE)
df_subset_random<-sample(df_subset, 1500)
df_subset_random<-df_subset[sample(nrow(df_subset), "1500"), ]
View(df_subset_random)
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
df_subset<-select(df, URL)
df_subset_random<-df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-select(df, URL)
df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-df_subset[sample(nrow(df_subset), "1500"), ]
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "1500"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
df_subset<-df_subset[sample(nrow(df_subset), "100"), ]
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "100"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
df_subset<-df_subset[sample(nrow(df_subset), "50"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
View(df_subset_lang)
####RUN####
df_subset<-df_subset[sample(nrow(df_subset), "3000"), ]
df<-read.csv2("app_M_H&F.csv", stringsAsFactors=FALSE)
anyDuplicated(df)
####RUN####
df_subset<-select(df, URL)
####RUN####
df_subset<-select(df, URL)
df_subset<-df_subset[sample(nrow(df_subset), "3000"), ]
df_subset<-tibble(URL=df_subset)
tic()
df_subset_lang <- df_subset %>%
rowwise() %>%
mutate(languages = possibly(~.x %>%
read_html() %>%
html_nodes(".section__description .we-clamp__contents") %>%
html_text(trim=TRUE) %>%
textcat(),
NA)(URL))
toc()
####r####
df_english_only<-df_subset_lang[which(language=="english"),]
View(df_subset_lang)
####r####
tic()
toc()
tic()
df_english_only<-df_subset_lang[which(languages=="english"),]
toc()
##
tic()
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
toc()
write.csv2(my.new.df, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
View(df_subset_lang)
View(df)
View(df_english_only)
write.csv2(df_english_only, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
write.csv2(df_subset_lang, "app_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
anyDuplicated(df_english_only)
anyDuplicated(df_subset_lang)
if(anyDuplicated(df_subset_lang)>0){
df_subset_lang <- df_subset_lang[!duplicated(paste(df_subset_lang$URL, df_subset_lang$languages)),]
}
anyDuplicated(df_subset_lang)
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
anyDuplicated(df_english_only)
write.csv2(df_subset_lang, "app_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
write.csv2(df_english_only, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
df_app<-select(df$Name, df$ID, df_english_only)
View(df)
df_app<-inner_join(df, df_english_only, by(URL=URL))
df_app<-inner_join(df, df_english_only, by("URL"="URL"))
df_app<-inner_join(df, df_english_only, by="URL"="URL")
df_app<-inner_join(df, df_english_only, by=c("URL"="URL")
df_app<-inner_join(df, df_english_only, by=c("URL"="URL"))
df_app<-inner_join(df, df_english_only, by="URL")
View(df_app)
anyDuplicated(df_app)
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
anyDuplicated(df_app)
if(anyDuplicated(df_subset_lang)>0){
df_subset_lang <- df_subset_lang[!duplicated(paste(df_subset_lang$URL, df_subset_lang$languages)),]
}
attach(df_subset_lang)
df_english_only<-df_subset_lang[which(languages=="english"),]
detach()
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
tic()
df_app<-inner_join(df, df_english_only, by="URL")
toc()
tic()
if(anyDuplicated(df_app)>0){
df_app <- df_app[!duplicated(paste(df_app$Name,df_app$URL, df_app$ID, df_app$languages)),]
}
toc()
write.csv2(df_subset_lang, "subset_M_H&F_ALL_LANGUAGES.csv",row.names=FALSE)
write.csv2(df_english_only, "subset_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
write.csv2(df_app, "app_M_H&F_ENGLISH_ONLY.csv",row.names=FALSE)
=======
2+2
<<<<<<< HEAD
# 1: Caricamento librerie ####
# General-purpose data wrangling
library(tidyverse)
source('~/GitHub/E-HEALTH/R script/getinfo.r', echo=TRUE)
install.packages("stringi")
source('~/GitHub/E-HEALTH/R script/getinfo.r', echo=TRUE)
=======
url<-"https://itunes.apple.com/us/app/human-anatomy-atlas-2019/id1117998129?mt=8"
page<-read_html(url)
source('~/Documents/GITHUB/E-HEALTH/R script/getappinfo.r', echo=TRUE)
#punteggio medio (DOUBLE)####
avgrating<-page%>%
html_nodes(".we-customer-ratings__averages__display")%>%
html_text(trim = TRUE)%>%
as.numeric(.)
#punteggio totale (DOUBLE)####
ratings<-page%>%
html_node(".we-customer-ratings__count")%>%
html_text(trim = TRUE)%>%
gsub(" Ratings", "", .)
ratings<-as.numeric(sub("K", "e3", ratings))
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%
html_text(trim=TRUE)%>%
str_extract(., pattern = pegipattern)%>%
as.numeric()
category<-page%>%
html_node(".large-6 .link")%>%
html_text(trim=TRUE)
description<-page%>%
html_node(".section__description .we-clamp__contents")%>%
html_text(trim=TRUE)
>>>>>>> Stashed changes
>>>>>>> 42a16b69edea4ac27d05d299f9457f7291a8c7be
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
for (i in 1){
url<-paste(dc[i])
page<-read_html(url[i])
#punteggio medio (DOUBLE)####
avgrating<-page%>%
html_nodes(".we-customer-ratings__averages__display")%>%   ##Prende la classe
html_text(trim = TRUE)%>%                                  ##sulla cosa che hai preso fammi diventare testo, trim=pulisci html
as.numeric(.)
##diventa numerico il . serve per prendere la riga prima
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%            ##prendi classe dove trovi etÃ 
html_text(trim=TRUE)%>%                                 ##pulisco
str_extract(., pattern = pegipattern)%>%                ##estrae in . (page)       corrisponde il pattern che ho selezionato sopra, prende cifre
as.numeric()
d=rbind(d, dataframe(avg=avgrating,pegix=pegi))
}
d = NULL
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
dc
for (i in 1){
url<-paste(dc[i])
page<-read_html(url)
##diventa numerico il . serve per prendere la riga prima
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%            ##prendi classe dove trovi etÃ 
html_text(trim=TRUE)%>%                                 ##pulisco
str_extract(., pattern = pegipattern)%>%                ##estrae in . (page)       corrisponde il pattern che ho selezionato sopra, prende cifre
as.numeric()
d=rbind(d, data.frame(pdb=pegi))
}
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
for (i in 2){
url<-paste(dc[i])
page<-read_html(url)
##diventa numerico il . serve per prendere la riga prima
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%            ##prendi classe dove trovi etÃ 
html_text(trim=TRUE)%>%                                 ##pulisco
str_extract(., pattern = pegipattern)%>%                ##estrae in . (page)       corrisponde il pattern che ho selezionato sopra, prende cifre
as.numeric()
d=rbind(d, data.frame(pdb=pegi))
}
d
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
for (i in 10){
url<-paste(dc[i])
page<-read_html(url)
##diventa numerico il . serve per prendere la riga prima
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%            ##prendi classe dove trovi etÃ 
html_text(trim=TRUE)%>%                                 ##pulisco
str_extract(., pattern = pegipattern)%>%                ##estrae in . (page)       corrisponde il pattern che ho selezionato sopra, prende cifre
as.numeric()
d=rbind(d, data.frame(pdb=pegi))
}
d
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
for (i in 100){
url<-paste(dc[i])
page<-read_html(url)
##diventa numerico il . serve per prendere la riga prima
pegipattern<-"\\d+"
pegi<-page%>%
html_node(".l-row:nth-child(6) .large-6")%>%            ##prendi classe dove trovi etÃ 
html_text(trim=TRUE)%>%                                 ##pulisco
str_extract(., pattern = pegipattern)%>%                ##estrae in . (page)       corrisponde il pattern che ho selezionato sopra, prende cifre
as.numeric()
d=rbind(d, data.frame(pdb=pegi))
}
d
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
View(d)
View(d)
dc
len
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
len
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
len<-length(dc)
for (i in len){
url<- paste(dc[i])
page<-read_html(url)
category<-page%>%
html_node(".large-6 .link")%>%                         ##prende la categoria, la classe in r gli devi dire .link
html_text(trim=TRUE)
d=rbind(d, category)
}
d
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
len<-length(dc)
for (i in len){
url<- paste(dc[i])
page<-read_html(url)
category<-page%>%
html_node(".large-6 .link")%>%                         ##prende la categoria, la classe in r gli devi dire .link
html_text(trim=TRUE)
d=rbind(d, data.frame(category))
}
d
source('~/GitHub/E-HEALTH/R script/CicloGetappinfo.R', echo=TRUE)
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
len<-length(dc)
cate<-NULL
for (i in len){
url<- paste(dc[i])
page<-read_html(url)
category<-page%>%
html_node(".large-6 .link")%>%                         ##prende la categoria, la classe in r gli devi dire .link
html_text(trim=TRUE)
cate<-c(cate,category)
}
cate
cate<-c(cate,category)''
cate<-c(cate,category)'
}
cate
cate<-c(cate,category)
cate<-c(cate,category)
for (i in len){
url<- paste(dc[i])
page<-read_html(url)
category<-page%>%
html_node(".large-6 .link")%>%                         ##prende la categoria, la classe in r gli devi dire .link
html_text(trim=TRUE)
cate<-c(cate,category)
}
cate
cate
cate
library(tidyverse)
library(rvest)
library(stringr)
library(rebus)
library(urltools)
library(gdata)
library(anytime)
library(dplyr)
library(lubridate)
d = NULL
df<-read.csv2("app_M_H&F_ENGLISH_ONLY.csv", stringsAsFactors = FALSE)
dc<- df[,2]
len<-length(dc)
cate<-NULL
for (i in 1:len){
url<- paste(dc[i])
page<-read_html(url)
category<-page%>%
html_node(".large-6 .link")%>%                         ##prende la categoria, la classe in r gli devi dire .link
html_text(trim=TRUE)
cate<-c(cate,category)
}
